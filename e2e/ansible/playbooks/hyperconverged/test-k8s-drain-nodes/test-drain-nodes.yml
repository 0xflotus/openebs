#Description: Verify behaviour of "kubectl drain" with OpenEBS volume replicas running on Nodes
#kubectl drain <node>: is one of the common procedures used to implement maintenance cycles on the nodes (hardware refresh, etc..,). With NodeAffinity/Stickiness, verify if is drain is successful.
#Author: Swarna
########################################################################################################################################################################
#Steps:
#1.Deploy openebs operator and storage classes.
#2.Check the maya-apiserver and openebs-provisioner are running
#3.Deploy percona application
#4.Check if the application and the volume pods are up and running.
#5.Check on which node replicas are running anf get the node names.
#6.Update the node names in patch.yaml.
#7.Patch the deployment to include node affinity spec.
#8.Drain the node on which replicas are running using "kubectl drain <nodename>" and check replicas are going to pending state.
#9.Perform cleanup.
########################################################################################################################################################################


- hosts: localhost

  vars_files:
    - kubectl-drain-vars.yml

  tasks:
   - block:



       - name: Get $HOME of K8s master for kubernetes user
         shell: source {{ profile }}; echo $HOME
         args:
           executable: /bin/bash
         register: result_kube_home
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Get the Number of nodes count
         shell: source {{ profile }}; kubectl get nodes | grep 'Ready' | grep 'none' | wc -l
         args:
           executable: /bin/bash
         register: node_out
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Fetch the node count from stdout
         set_fact:
            node_count: " {{ node_out.stdout}}"


       - name: Check whether maya-apiserver pod is deployed
         shell: source ~/.profile; kubectl get pods --all-namespaces | grep maya-apiserver
         args:
           executable: /bin/bash
         register: result
         until: "'Running' in result.stdout"
         delay: 120
         retries: 5
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Start the log aggregator to capture test pod logs
         shell: >
           source {{ profile }};
           nohup stern "{{test_pod_regex}}" --since 1m > "{{result_kube_home.stdout}}/{{test_log_path}}" &
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Obtaining storage classes yaml
         shell: kubectl get sc openebs-percona -o yaml > "{{ create_sc }}"
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Replace the replica count in openebs-storageclasses yaml
         replace:
           path: "{{ create_sc }}"
           regexp: 'openebs.io/jiva-replica-count: "3"'
           replace: 'openebs.io/jiva-replica-count: "{{ (node_count) |int-1 }}"'
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Delete the existing storage class and create new one
         shell: kubectl delete sc openebs-percona; kubectl apply -f "{{ create_sc }}"
         args:
           executable: /bin/bash
         register: sc_out
         until: "'created' in sc_out.stdout"
         delay: 10
         retries: 5
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"



       - name: Deploy percona application
         shell: source {{ profile }}; kubectl apply -f {{ percona_link }}
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Confirm if the percona pod is running
         shell: source ~/.profile; kubectl get pods --all-namespaces | grep percona
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         register: result
         until: "'percona' and 'Running' in result.stdout"
         delay: 120
         retries: 10

       - name: Check if the replica pods are created and running
         shell: source ~/.profile; kubectl get pods --all-namespaces | grep rep | grep -i running |wc -l
         args:
           executable: /bin/bash
         register: rep_count
         until: "'2' in rep_count.stdout"
         delay: 60
         retries: 5
         ignore_errors: true
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Get PV name
         shell: source ~/.profile; kubectl get pv | grep openebs-percona | awk '{print $1}'
         args:
           executable: /bin/bash
         register: pv_name
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Copy replica_patch.yaml to master
         copy:
           src: "{{ patch_file }}"
           dest: "{{ result_kube_home.stdout }}"
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Get the node name where replica1 is scheduled
         shell: source ~/.profile; kubectl get po --all-namespaces -o wide | grep "{{ pv_name.stdout }}" | grep rep | awk '{print $8}' | awk 'FNR == 1 {print}'
         args:
           executable: /bin/bash
         register: node1
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Get the node name where replica2 is scheduled
         shell: source ~/.profile; kubectl get po --all-namespaces -o wide | grep "{{ pv_name.stdout }}" | grep rep | awk '{print $8}' | awk 'FNR == 2 {print}'
         args:
           executable: /bin/bash
         register: node2
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Update replica1 node name in replica_patch file
         replace:
           path: "{{ result_kube_home.stdout }}/{{ patch_file }}"
           regexp: 'nodename_where_replica_pod_1_got_scheduled'
           replace: '{{ node1.stdout }}'
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Update replica2 node name in replica_patch file
         replace:
           path: "{{ result_kube_home.stdout }}/{{ patch_file }}"
           regexp: 'nodename_where_replica_pod_2_got_scheduled'
           replace: '{{ node2.stdout }}'
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Get the deployment namee
         shell: source ~/.profile; kubectl get deploy --all-namespaces |grep "{{ pv_name.stdout }}" | grep rep |awk '{print $2}'
         args:
           executable: /bin/bash
         register: deploy_name
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Apply the node affinity property
         shell: source ~/.profile; kubectl patch deployment "{{ deploy_name.stdout }}" -p "$(cat replica_patch.yaml)"
         args:
           executable: /bin/bash
         register: patch_out
         until: "'patched' in patch_out.stdout"
         delay: 20
         retries: 5
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"


       - name: Drain the node where replica is scheduled
         shell: source ~/.profile; kubectl drain {{ node1.stdout }} --ignore-daemonsets --force
         args:
           executable: /bin/bash
         register: result
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Check the available replicas in deployment
         shell: kubectl get deploy --all-namespaces | grep "{{ pv_name.stdout }}" | grep rep | awk '{print $6}'
         args:
           executable: /bin/bash
         register: available_pods
         until: "'2' in available_pods.stdout"
         delay: 30
         retries: 5
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"
         ignore_errors: true


       - name: Check if the replica is in pending state after node drain
         shell: kubectl get pods --all-namespaces -o wide | grep "{{ pv_name.stdout }}" | grep rep | grep Pending
         args:
           executable: /bin/bash
         register: result
         until: "'Pending' in result.stdout"
         delay: 30
         retries: 15
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Terminate the log aggregator
         shell: source ~/.profile; killall stern
         args:
           executable: /bin/bash
         delegate_to: "{{groups['kubernetes-kubemasters'].0}}"

       - name: Set flag to pass if test case is passed
         set_fact:
           flag: "Pass"

     rescue:
       - name: Set flag to fail if test case is failed
         set_fact:
           flag: "Fail"

     always:

       - include: cleanup.yml
         when: clean | bool

       - name: Send slack notification
         slack:
           token: "{{ lookup('env','SLACK_TOKEN') }}"
           msg: '{{ ansible_date_time.time }} TEST: {{test_name}}, RESULT: {{ flag }}'
         when: slack_notify | bool and lookup('env','SLACK_TOKEN')


