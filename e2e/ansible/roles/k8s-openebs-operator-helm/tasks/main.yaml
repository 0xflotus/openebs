---
# Steps
# 1) Downloading helm
# 2) Initialising helm
# 3) Check if the tiller is deployed
# 4) Create service account for tiller
# 5) Create cluster role binding
# 6) Update the deployment with the service account
# 7) Install OpenEBS using stable helm chart
# 8) Check if the installation is successful
# 9) Create the default storage classes

- name: 1) Getting the home directory of kubernetes master.
  shell: source ~/.profile; echo $HOME
  args:
    executable: /bin/bash
  register: result_kube_home

- name: Install helm client
  shell: curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash
  args:
    executable: /bin/bash
  register: output
  until: "'installed' in output.stdout"
  delay: 30
  retries: 5

- wait_for: timeout=30

- name: 2a) Tiller setup.
  shell: helm init
  args:
    executable: /bin/bash
  register: tiller_out
  until: "'Happy Helming' in tiller_out.stdout"
  delay: 30
  retries: 15

- name: 3) Checking if the tiller pod is created.
  shell: helm version
  args:
    executable: /bin/bash
  register: tiller_version
  until: "'Server: &version.Version' in tiller_version.stdout"
  delay: 60
  retries: 15

- block:

    - name: 4) Checking if the tiller service account already exists.
      shell: source ~/.profile; kubectl get sa -n kube-system | grep tiller
      args:
        executable: /bin/bash
      register: sa
      until: "'tiller' in sa.stdout"
      delay: 20
      retries: 2
  
  rescue:
     
    - name: 4a) Creating the service account
      shell: source ~/.profile; kubectl -n kube-system create sa tiller
      args:
        executable: /bin/bash
      register: tiller
      until: "'\"tiller\" created' in tiller.stdout"
      delay: 60
      retries: 5
  
- block:

     - name: 5) Checking if the tiller cluster role binding already exists.
       shell: source ~/.profile; kubectl get clusterrolebinding | grep tiller
       args:
         executable: /bin/bash
       register: cr
       until: "'tiller' in cr.stdout"
       delay: 10
       retries: 2

  rescue:

     - name: 5a) Creating the cluster rolebinding.
       shell: source ~/.profile; kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
       args:
         executable: /bin/bash
       register: crb
       until: "'\"tiller\" created' in crb.stdout"
       delay: 60
       retries: 5

- name: 6) Copying the patch yaml file to kubernetes master.
  copy:
    src: "{{ update_deploy_file }}"
    dest: "{{ result_kube_home.stdout }}"

- name : 6a) Updating the tiller-deploy deployment with the service account.
  shell: source ~/.profile; kubectl -n kube-system patch deploy/tiller-deploy -p "$(cat {{result_kube_home.stdout}}/{{ update_deploy_file }})"
  args:
    executable: /bin/bash
  register: tiller_deploy
  until: "'\"tiller-deploy\" patched' in tiller_deploy.stdout"
  delay: 60
  retries: 6

# Installing openebs using stable chart in openebs namespace. The chart will be created with some random name.
# We can verify it using "helm ls --all" command.
- name: 7) Installing openebs using stable charts.
  shell: >
    helm install stable/openebs --set apiserver.imageTag={{ apiserver_version }} --set provisioner.imageTag={{ provisioner_version }} --set jiva.imageTag={{ jiva_version}} 
    --set snapshotOperator.provisioner.imageTag={{ snapshot_provisioner_version }} --set snapshotOperator.controller.imageTag={{ snapshot_controller_version }} --namespace {{ namespace }}
  args:
    executable: /bin/bash
  register: openebs_out
  until: "'The OpenEBS has been installed' in openebs_out.stdout"
  delay: 120
  retries: 5

# Checking if the OpenEBS components such as provisioner, apiserver and snapshot operator are up and running.

- name: 8) Checking if the provisioner is up.
  shell: source ~/.profile; kubectl get pods -n "{{ namespace }}" | grep "provisioner"
  args:
    executable: /bin/bash
  register: deployment
  until: "'Running' in deployment.stdout"
  delay: 60
  retries: 15

- name: 8a) Checking if the openebs-apiserver is up.
  shell: source ~/.profile; kubectl get pods -n "{{ namespace }}" | grep "apiserver"
  args:
    executable: /bin/bash
  register: api_server
  until: "'Running' in api_server.stdout"
  delay: 60
  retries: 15

- name: 8b) Checking of the snapshot-operator is up.
  shell: source ~/.profile; kubectl get pods -n {{ namespace }} | grep "snapshot-operator"
  args:
    executable: /bin/bash
  register: operator
  until: "'Running' in operator.stdout"
  delay: 60
  retries: 15 

- name: 9) Creating the default storage classes
  shell: source ~/.profile; kubectl apply -f "{{ storage_classes }}"
  args:
    executable: /bin/bash


